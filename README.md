ğŸš€ AWS Lambda Job Scraper (v0.5)
This AWS Lambda project automates job searching by pulling job listings from multiple RSS feeds, storing them in S3, and sending email notifications. It also prevents duplicate jobs using DynamoDB.

ğŸ“Œ Features
âœ… Fetches jobs from multiple RSS feeds every 20 minutes
âœ… Stores job listings in S3 as CSV files
âœ… Sends email notifications via AWS SES
âœ… Uses DynamoDB to prevent duplicate job listings

ğŸ› ï¸ Tech Stack
AWS Lambda â€“ Serverless function for automation
AWS S3 â€“ Stores job data as CSV files
AWS SES â€“ Sends job listing notifications via email
AWS DynamoDB â€“ Tracks job postings to avoid duplicates
EventBridge â€“ Schedules execution every 20 minutes
Python â€“ Processes RSS feeds and handles data storage
ğŸš€ Setup & Deployment
1ï¸âƒ£ AWS Configuration
Before running this project, ensure you have:
âœ… AWS CLI configured
âœ… An IAM Role with Lambda, S3, SES, and DynamoDB permissions
âœ… A verified email in AWS SES
âœ… A DynamoDB table named JobListings

2ï¸âƒ£ Clone the Repository
git clone https://github.com/YOUR_GITHUB_USERNAME/aws-lambda-job-scraper.git
cd aws-lambda-job-scraper

3ï¸âƒ£ Install Dependencises
pip install -r requirements.txt

4ï¸âƒ£ Deploy to AWS Lambda
    1.  Zip the function
    2.  Upload to AWS Lambda Console
    3.  Schedule with EventBridge (rate(20 minutes))
    
    ğŸ› ï¸ How It Works

1ï¸âƒ£ The Lambda function fetches job listings from RSS feeds
2ï¸âƒ£ It checks DynamoDB â†’ If a job is already stored, itâ€™s skipped
3ï¸âƒ£ New jobs are:
    â€¢   âœ… Saved to S3 as a CSV file
    â€¢   âœ… Emailed via AWS SES
4ï¸âƒ£ The next run only includes fresh job listings
